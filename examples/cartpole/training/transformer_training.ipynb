{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer ILQR Training\n",
    "\n",
    "This notebook demonstrates the step-by-step training process of the Transformer ILQR model. The notebook:\n",
    "\n",
    "- Loads ILQR log data from a pickle file\n",
    "- Processes the data into a pandas DataFrame\n",
    "- Splits the data into training and testing sets\n",
    "- Trains and saves the Transformer model using the training set\n",
    "\n",
    "After training, the loss history is available for external plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Import required functions from transforerm_training.py\n",
    "from transformer_training import load_ilqr_logs, process_ilqr_logs, split_data, train_transformer\n",
    "\n",
    "print('Imports successful.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load ILQR Logs\n",
    "Specify the path to your ILQR logs pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ILQR logs from combined_ilqr_logs_range_-0.500_0.500_angle_-0.500_0.500.pkl...\n",
      "Loaded 14694 log entries.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the combined ILQR logs file\n",
    "log_file_path = \"combined_ilqr_logs_range_-0.500_0.500_angle_-0.500_0.500.pkl\"\n",
    "\n",
    "ilqr_logs = load_ilqr_logs(log_file_path)\n",
    "if ilqr_logs is None:\n",
    "    raise ValueError('Failed to load ILQR logs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process ILQR Logs\n",
    "Convert the raw log entries into a pandas DataFrame for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data from logs:\n",
      "   iteration                                              x_seq  \\\n",
      "0          0  [[-0.5, 0.0, -0.5, 0.0], [-0.5, -0.00297010799...   \n",
      "1          1  [[-0.5, 0.0, -0.5, 0.0], [-0.5, 0.368641435805...   \n",
      "2          2  [[-0.5, 0.0, -0.5, 0.0], [-0.5, 0.389105586497...   \n",
      "3          0  [[-0.5229970544109485, -2.2997054410948463, -0...   \n",
      "4          1  [[-0.5229970544109485, -2.2997054410948463, -0...   \n",
      "\n",
      "                                               u_seq  current_cost  \\\n",
      "0  [[43.2756244280376], [22.09060854899219], [8.6...    116.545056   \n",
      "1  [[45.65875518470563], [24.835771335262205], [1...     80.472424   \n",
      "2  [[45.81731334682083], [25.03253152858651], [10...     80.351792   \n",
      "3  [[32.568968411348095], [11.004713093521609], [...    356.571723   \n",
      "4  [[35.57533949571867], [12.42922332976994], [-4...    327.327521   \n",
      "\n",
      "                                               k_seq  \\\n",
      "0  [[43.2756244280376], [40.852642825333255], [38...   \n",
      "1  [[2.38313075666803], [3.776087470077054], [4.0...   \n",
      "2  [[0.15855816211519855], [0.2652867150436463], ...   \n",
      "3  [[7.536436882761588], [3.720736385887708], [-1...   \n",
      "4  [[3.006371084370575], [2.72900483649392], [1.8...   \n",
      "\n",
      "                                               K_seq  alpha  \\\n",
      "0  [[[-18.49854376422683, -6.772577956663022, -68...    1.0   \n",
      "1  [[[-22.473491337737233, -8.789049163787213, -8...    1.0   \n",
      "2  [[[-22.750924952727487, -8.92204673319014, -82...    1.0   \n",
      "3  [[[-27.128842781345888, -10.789192782676638, -...    1.0   \n",
      "4  [[[-28.11710059015215, -11.372577073121859, -7...    1.0   \n",
      "\n",
      "                                           new_x_seq  \\\n",
      "0  [[-0.5, 0.0, -0.5, 0.0], [-0.5, 0.368641435805...   \n",
      "1  [[-0.5, 0.0, -0.5, 0.0], [-0.5, 0.389105586497...   \n",
      "2  [[-0.5, 0.0, -0.5, 0.0], [-0.5, 0.390467139200...   \n",
      "3  [[-0.5229970544109485, -2.2997054410948463, -0...   \n",
      "4  [[-0.5229970544109485, -2.2997054410948463, -0...   \n",
      "\n",
      "                                           new_u_seq    new_cost  found_update  \n",
      "0  [[43.2756244280376], [22.09060854899219], [8.6...   80.472424          True  \n",
      "1  [[45.65875518470563], [24.835771335262205], [1...   80.351792          True  \n",
      "2  [[45.81731334682083], [25.03253152858651], [10...   80.351205          True  \n",
      "3  [[32.568968411348095], [11.004713093521609], [...  327.327521          True  \n",
      "4  [[35.57533949571867], [12.42922332976994], [-4...  327.038587          True  \n"
     ]
    }
   ],
   "source": [
    "df = process_ilqr_logs(ilqr_logs)\n",
    "print('Sample data from logs:')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split the Data\n",
    "Shuffle and split the DataFrame into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 11755\n",
      "Test set size: 2939\n",
      "Training set size: 11755\n",
      "Test set size: 2939\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = split_data(df, train_fraction=0.8, random_state=42)\n",
    "\n",
    "print('Training set size:', len(train_df))\n",
    "print('Test set size:', len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and Save the Transformer Model\n",
    "Train the Transformer ILQR model using the training DataFrame. You can adjust hyperparameters as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer Loaded. Device is: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset: 100%|██████████| 11755/11755 [00:00<00:00, 50607.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerPredictor(\n",
      "  (state_embed): Linear(in_features=4, out_features=256, bias=True)\n",
      "  (control_embed): Linear(in_features=5, out_features=256, bias=True)\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (output_linear): Linear(in_features=256, out_features=5, bias=True)\n",
      "  (transformer_decoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Loss: 0.360672\n",
      "Training completed.\n",
      "Model saved to 20250408_2316_cartpole_decoder_dec3_dmodel256_nhead8_ff256_drop0.1_epoch1_promptlen1_1.2M/tf_model.pt\n",
      "Normalizer and hyperparameters saved to 20250408_2316_cartpole_decoder_dec3_dmodel256_nhead8_ff256_drop0.1_epoch1_promptlen1_1.2M/tf_model_normalizer.npz.\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set training hyperparameters\n",
    "num_epochs = 1       # Adjust number of epochs\n",
    "batch_size = 128     \n",
    "learning_rate = 1e-4 \n",
    "prompt_len = 1    \n",
    "d_model = 256        \n",
    "nhead = 8            \n",
    "\n",
    "model_wrapper = train_transformer(train_df,\n",
    "                                  num_epochs=num_epochs,\n",
    "                                  batch_size=batch_size,\n",
    "                                  learning_rate=learning_rate,\n",
    "                                  prompt_len=prompt_len,\n",
    "                                  d_model=d_model,\n",
    "                                  nhead=nhead)\n",
    "\n",
    "print('Training completed.')\n",
    "\n",
    "# Save the trained model\n",
    "model_wrapper.save(\"cartpole\")\n",
    "print('Model saved successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loss History\n",
    "The training loss history is stored in `model_wrapper.train_loss_history`.\n",
    "You can plot these loss curves externally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss history: [0.4300576684754841]\n"
     ]
    }
   ],
   "source": [
    "print('Train loss history:', model_wrapper.train_loss_history)\n",
    "if hasattr(model_wrapper, 'test_loss_history'):\n",
    "    print('Test loss history:', model_wrapper.test_loss_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quattro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
